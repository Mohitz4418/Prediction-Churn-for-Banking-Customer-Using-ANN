{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an ANN\n",
    "\n",
    "This can be challenging and often requires expreimentation. however, there are some guidelines and methods that can help in making an informed decision :\n",
    "\n",
    "1. Start Simple : Begin with a simple architecture and gradually increase complexity if needed.\n",
    "2. Grid Search / Random Search : Use grid search or random search to try different architectures.\n",
    "3. Cross Validation : Use this to evaluate the performance of different architectures.\n",
    "4. Heuristics and Rules of Thunb : Some heuristic and empirical rules can provide starting point, such as :\n",
    "    \n",
    "    i. The number of neurins in the hidden layer should be between the size of the input layer and the size of the output layer\n",
    "    \n",
    "    ii. A common practive is to start with 1 - 2 hidden layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder,OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "data = data.drop([\"RowNumber\", \"CustomerId\", \"Surname\"], axis = 1)\n",
    "\n",
    "Label_encoder_gender = LabelEncoder()\n",
    "data[\"Gender\"] = Label_encoder_gender.fit_transform(data[\"Gender\"])\n",
    "\n",
    "one_hot_encoder_geo = OneHotEncoder(handle_unknown = \"ignore\")\n",
    "geo_encoded = one_hot_encoder_geo.fit_transform(data[[\"Geography\"]]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns = one_hot_encoder_geo.get_feature_names_out([\"Geography\"]))\n",
    "\n",
    "data = pd.concat([data.drop(\"Geography\", axis = 1), geo_encoded_df], axis = 1)\n",
    "\n",
    "X = data.drop(\"Exited\", axis = 1)\n",
    "y = data[\"Exited\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Label_encoder_gender.pkl\", \"wb\") as file:\n",
    "    pickle.dump(Label_encoder_gender, file)\n",
    "\n",
    "with open(\"one_hot_encoder_geo.pkl\", \"wb\") as file:\n",
    "    pickle.dump(one_hot_encoder_geo, file)\n",
    "\n",
    "with open(\"scaler.pkl\", \"wb\") as file:\n",
    "     pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create a model and try different parameters (KerasClassifier)\n",
    "\n",
    "def create_model(neurons = 32, layers = 1):\n",
    "    model =Sequential()\n",
    "    model.add(Dense(neurons, activation = \"relu\", input_shape = (X_train.shape[1],)))\n",
    "    \n",
    "    for _ in range(layers - 1):\n",
    "        model.add(Dense(neurons, activation = \"relu\"))\n",
    "\n",
    "    model.add(Dense(1, activation = \"sigmoid\"))\n",
    "    model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a keras classifier\n",
    "\n",
    "model = KerasClassifier(layers = 1, neurons = 32, build_fn = create_model, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    \"neurons\" : [16, 32, 64, 128],\n",
    "    \"layers\" : [ 1, 2, 3],\n",
    "    \"epochs\" : [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator = model, param_grid = param_grid, n_jobs = -1, cv = 3, verbose = 1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best : %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
